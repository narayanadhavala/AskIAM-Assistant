# AskIAM Assistant - AI-Powered IAM Access Validation

An intelligent IAM (Identity and Access Management) assistant that validates user access requests using LLM-based decision-making with RAG (Retrieval Augmented Generation) and a multi-tool validation pipeline.

---

## ğŸ“‹ Project Overview

The AskIAM Assistant provides an intelligent chatbot interface for validating IAM access requests. It combines:
- **RAG Engine**: Vector search on IAM metadata using ChromaDB
- **LLM Processing**: Natural language understanding via Ollama
- **MCP Tools**: SQL generation and validation for entity verification
- **Comprehensive Tracing**: Full execution trace logging for audit purposes

---

## ğŸ“ Directory Structure

```
AskIAM-Assistant/
â”œâ”€â”€ backend/                         # Main application (current active version)
â”‚   â”œâ”€â”€ app.py                       # Gradio UI entry point
â”‚   â”œâ”€â”€ orchestrator.py              # Request routing (RAG â†’ MCP)
â”‚   â”œâ”€â”€ config.yaml                  # Configuration (LLM, ChromaDB, tools)
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â”œâ”€â”€ core/                        # Core utilities
â”‚   â”‚   â”œâ”€â”€ config_loader.py         # YAML config loader
â”‚   â”‚   â”œâ”€â”€ model_factory.py         # LLM & embeddings factory
â”‚   â”‚   â””â”€â”€ types.py                 # Type definitions
â”‚   â”œâ”€â”€ mcp/                         # Model Context Protocol tools
â”‚   â”‚   â”œâ”€â”€ trace.py                 # Trace handler & session manager
â”‚   â”‚   â”œâ”€â”€ extract.py               # Request extraction
â”‚   â”‚   â”œâ”€â”€ validators.py            # Entity validation
â”‚   â”‚   â”œâ”€â”€ graph.py                 # MCP orchestration
â”‚   â”‚   â””â”€â”€ tools/
â”‚   â”‚       â”œâ”€â”€ entity_validator.py  # Generic entity validator
â”‚   â”‚       â”œâ”€â”€ sql_generator.py     # SQL generation tool
â”‚   â”‚       â””â”€â”€ sql_validator.py     # SQL safety validator
â”‚   â””â”€â”€ rag/                         # RAG pipeline
â”‚       â”œâ”€â”€ rag_engine.py            # RAG similarity search & LLM validation
â”‚       â””â”€â”€ vectorstore.py           # ChromaDB vector store initialization
â”‚
â”œâ”€â”€ database/                        # Database setup
â”‚   â”œâ”€â”€ iam_sample_data.sql         # Sample IAM data (Users, Apps, Roles)
â”‚   â””â”€â”€ chromaDB/
â”‚       â”œâ”€â”€ ingest.py               # Ingest IAM data into ChromaDB
â”‚       â””â”€â”€ test-chroma.py          # Test ChromaDB queries
â”‚
â”œâ”€â”€ ReadME.md                        
â”œâ”€â”€ requirements.txt                 # Root-level dependencies
â””â”€â”€ tools.yaml                       # MCP toolbox configuration

```

---

## âš™ï¸ Prerequisites

- **OS**: Linux/macOS/Windows (Linux recommended)
- **Python**: 3.9+
- **Docker**: For MySQL, ChromaDB, Toolbox
- **Ollama**: For running LLMs locally

---

## ğŸš€ Setup Instructions

### Step 1: Clone/Extract the Project

```bash
cd /path/to/AskIAM-Assistant
cd backend  # Enter the main application directory
```

### Step 2: Install Python Dependencies

```bash
pip install -r requirements.txt
```

### Step 3: Start Docker Services

#### 3.1 MySQL Database

```bash
docker pull mysql:8.0
docker run -d --name iam-mysql \
  -e MYSQL_ROOT_PASSWORD=root123 \
  -p 3306:3306 \
  mysql:8.0

# Wait 30 seconds for initialization
sleep 30

# Load sample data
mysql -h 127.0.0.1 -u root -proot123 < ../database/iam_sample_data.sql
```

#### 3.2 ChromaDB (Vector Store)

```bash
docker pull chromadb/chroma:latest
docker run -d --name chromadb \
  -p 8000:8000 \
  chromadb/chroma:latest
```

#### 3.3 Toolbox (MCP Server for SQL Execution)

```bash
docker run -d --name iam-toolbox \
  -p 5000:5000 \
  --network host \
  -v "$(pwd)/../tools.yaml:/app/tools.yaml" \
  us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:0.23.0
```

### Step 4: Start Ollama

In a separate terminal:

```bash
ollama serve

# In another terminal, pull required models
ollama pull nomic-embed-text
ollama pull llama3.1:8b
```

### Step 5: Ingest IAM Data into ChromaDB

```bash
python ../database/chromaDB/ingest.py
```

### Step 6: Start the Application

```bash
python app.py
```

The app will launch on `http://localhost:7860`

---

## ğŸ“Š Request Processing Flow

```
User Query
    â†“
[Orchestrator] (orchestrator.py)
    â”œâ”€â†’ [RAG Validation] (rag_engine.py)
    â”‚   â”œâ”€â†’ Vector similarity search (ChromaDB)
    â”‚   â”œâ”€â†’ LLM decision (Ollama)
    â”‚   â””â”€â†’ Return (if confident)
    â”‚
    â”œâ”€â†’ [MCP Validation] (graph.py)
    â”‚   â”œâ”€â†’ Extract request parameters (extract.py)
    â”‚   â”œâ”€â†’ Validate entities (validators.py)
    â”‚   â”‚   â”œâ”€â†’ Generate SQL (sql_generator.py)
    â”‚   â”‚   â”œâ”€â†’ Validate SQL (sql_validator.py)
    â”‚   â”‚   â””â”€â†’ Execute via Toolbox
    â”‚   â””â”€â†’ Return result
    â”‚
    â””â”€â†’ [Response to User]
         â””â”€â†’ [Full Trace Logged] (trace.py)
```

---

## ğŸ” Tracing System

The application includes comprehensive execution tracing:

### During Active Session
- Individual steps printed to console
- Shows tool calls with inputs/outputs
- Real-time feedback on validation process

### On Session End
- Complete accumulated trace printed
- Includes all requests from the session
- Exported to JSON with full details

### Trace File Location
- Default: `iam_trace_chat_session_YYYYMMDD_HHMMSS.json`
- Cache file: `.trace_session_cache` (tracks current session)

### Example Trace Structure
```json
{
  "session_timestamp": "2026-01-12T07:33:44",
  "total_requests": 2,
  "total_steps": 4,
  "stack": [
    {
      "step": 1,
      "tool": "rag_similarity_search",
      "input": { "query": "I need HR Analyst in Workday", "k": 1 },
      "output": "Retrieved 1 document(s): [...]"
    },
    ...
  ]
}
```

---

## ğŸ”§ Configuration

Edit `backend/config.yaml`:

```yaml
ollama:
  base_url: http://localhost:11434
  llm_model: llama3.1:8b
  embedding_model: nomic-embed-text

chroma:
  host: localhost
  port: 8000
  collection: iam-metadata

toolbox:
  url: http://127.0.0.1:5000

ui:
  title: IAM Access Assistant

entities:
  user:
    table: Users
    id_column: UserID
    name_column: UserName
    error: Invalid user
  # ... more entities
```

---

## ğŸ“ Usage

### Web UI

1. Open `http://localhost:7860`
2. Type your access request:
   - "I need access to the HR Analyst role in the Workday application"
   - "Aaron.Nichols needs the Finance Manager role in NetSuite"
3. View the response (VALID or INVALID)
4. On app close, see the full session trace printed

### Command Line (Testing)

```bash
# Direct Python import
python -c "
from orchestrator import handle_request
result = handle_request('I need HR Analyst in Workday')
print(result)
"
```

---

## âœ… Validation Checklist

Before running the app:

- [ ] Python 3.9+ installed
- [ ] Docker running (all 3 containers up)
- [ ] Ollama running with models pulled
- [ ] MySQL has sample data (`SELECT * FROM iamdb.Users`)
- [ ] ChromaDB has ingested data (run ingest.py)
- [ ] Toolbox is responding (`curl http://127.0.0.1:5000`)

---

## ğŸ—ï¸ Architecture Components

### RAG Engine (`rag/rag_engine.py`)
- Semantic search on IAM metadata
- LLM-based validation
- Fallback to MCP if uncertain

### MCP Tools (`mcp/tools/`)
- **SQL Generator**: Creates safe SELECT queries
- **SQL Validator**: Prevents SQL injection
- **Entity Validator**: Checks Users/Apps/Roles tables

### Trace System (`mcp/trace.py`)
- `MCPTraceHandler`: Captures tool execution
- `TraceManager`: Singleton session management
- Automatic JSON export on request completion

---

## ğŸ“š Key Files Explained

| File | Purpose |
|------|---------|
| `app.py` | Gradio UI + session lifecycle |
| `orchestrator.py` | Routes requests to RAG or MCP |
| `rag_engine.py` | Vector search + LLM validation |
| `graph.py` | MCP orchestration & pipeline |
| `extract.py` | NLU for request parameters |
| `validators.py` | Entity validation pipeline |
| `trace.py` | Consolidated tracing system |
| `config.yaml` | All service configurations |

---

## ğŸ—‘ï¸ Cleanup

### Stop All Services

```bash
docker stop iam-mysql chromadb iam-toolbox
docker rm iam-mysql chromadb iam-toolbox
```

### Clean Trace Files

```bash
rm -f iam_trace*.json .trace_session_cache
```

---

## ğŸ“ Notes

- Keep Docker running while using the app
- Ollama must be active before starting the application
- Trace files persist between sessions (useful for auditing)
- Use `.gitignore` to ignore trace files and cache
- Configuration is YAML-based for easy customization

---

## ğŸ” Security

- All SQL queries are validated before execution
- Only SELECT statements allowed (no INSERT/UPDATE/DELETE)
- Queries restricted to specific tables (Users, Apps, Roles)
- LLM decisions can be audited via trace logs

---

## ğŸ“ Support

For issues:
1. Check the trace output for detailed execution logs
2. Review `config.yaml` for service URLs
3. Verify all Docker containers are running
4. Check Ollama model availability

---

**Last Updated**: January 12, 2026  
**Version**: 2.0 (RAG + MCP Pipeline)
